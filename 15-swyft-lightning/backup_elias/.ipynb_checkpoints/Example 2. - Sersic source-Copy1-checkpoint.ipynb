{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3822aac4-d5eb-4979-b237-70c80d2489e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0297c907",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import swyft\n",
    "import swyft.lightning as sl\n",
    "import lensing_model\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "from pyrofit.lensing.sources import SersicSource\n",
    "\n",
    "import sys\n",
    "sys.path.append('../16-swyft_unet/scripts/')\n",
    "from plot import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d83b8b-4b96-4f92-b71b-84ecba33cc68",
   "metadata": {},
   "source": [
    "## Problem-specific analysis components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db2c3024-004e-4ad1-8e9a-93999f462752",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]/home/eliasd/lensing/pyrofit-utils/pyrofit/utils/torchutils.py:126: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return (indices.unsqueeze(-1) // strides) % shape\n",
      "100%|██████████| 3/3 [00:03<00:00,  1.04s/it]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2137.77it/s]\n"
     ]
    }
   ],
   "source": [
    "KNN = 3\n",
    "SIGMA = 0.02\n",
    "NPIX_SRC = NPIX_IMG = 40\n",
    "\n",
    "class Model(sl.SwyftModel):\n",
    "    def slow(self, pars):\n",
    "        torch.cuda.set_device(0)\n",
    "        torch.set_default_tensor_type(torch.cuda.FloatTensor)    \n",
    "        x, y, phi, q, r_ein, slope = pars['z_lens']\n",
    "        slope = 2.0\n",
    "        x_src, y_src, phi_src, q_src, index, r_e, I_e = pars['z_src']\n",
    "        img, coords = lensing_model.image_generator_sersic(x, y, phi, q, r_ein, slope, x_src, y_src, phi_src, q_src, index, r_e, I_e)\n",
    "        X, Y, Xsrc, Ysrc = coords\n",
    "        kNN_idx = lensing_model.get_kNN_idx(X/5, -Y/5, Xsrc, Ysrc, k = KNN)  # TODO: Need to sort out strange 1/5 and -1/5 factors\n",
    "        torch.set_default_tensor_type(torch.FloatTensor)\n",
    "        return sl.SampleStore(mu = img.cpu(), kNN_idx = kNN_idx.cpu(), X = X.cpu(), Y = Y.cpu(), Xsrc = Xsrc.cpu(), Ysrc = Ysrc.cpu())\n",
    "    \n",
    "    def fast(self, d):\n",
    "        img = d['mu'] + torch.randn_like(d['mu'])*SIGMA\n",
    "        return sl.SampleStore(img=img)\n",
    "    \n",
    "    def prior(self, N, bounds = None):\n",
    "        src_samples = self.prior_sersic(N, bounds = bounds)\n",
    "        lens_samples = self.prior_lens(N, bounds = bounds)\n",
    "        return sl.SampleStore(**src_samples, **lens_samples)\n",
    "    \n",
    "    # Draw from source prior\n",
    "#     def prior_src(self, N, bounds = None):\n",
    "#         if bounds is None or 'z_src' not in bounds:\n",
    "#             R = lensing_model.RandomSource()\n",
    "#             z_src = torch.stack([R().cpu() for _ in range(N)])\n",
    "#         else:\n",
    "#             n = 3\n",
    "#             l, h = bounds['z_src'].low, bounds['z_src'].high\n",
    "#             R = lensing_model.RandomSource()\n",
    "#             z_src = []\n",
    "#             for _ in range(N):\n",
    "#                 rnd = sum([R().cpu()-R().cpu() for _ in range(n)])\n",
    "#                 rnd -= rnd.min()\n",
    "#                 rnd /= rnd.max()\n",
    "#                 z_src.append(l+rnd*h)\n",
    "#             z_src = torch.stack(z_src)\n",
    "#         return sl.SampleStore(z_src=z_src)\n",
    "\n",
    "    def prior_sersic(self, N, bounds = None):\n",
    "        if bounds is not None:\n",
    "            low = bounds['z_src'].low\n",
    "            high = bounds['z_src'].high\n",
    "        else:\n",
    "            low =  np.array([-0.1, -0.1, 0, 0., 0.5, 0.1, 0.])\n",
    "            high = np.array([0.1, 0.1, 1.5, 1., 4.0, 2.5, 4.])\n",
    "        draw = np.array([np.random.uniform(low=low, high=high) for _ in range(N)])\n",
    "        return sl.SampleStore(z_src = torch.tensor(draw).float())\n",
    "\n",
    "    def prior_lens(self, N, bounds = None):\n",
    "        if bounds is not None:\n",
    "            low = bounds['z_lens'].low\n",
    "            high = bounds['z_lens'].high\n",
    "        else:\n",
    "            low =  np.array([-0.2, -0.2, 0, 0.2, 1.0, 1.5])\n",
    "            high = np.array([0.2, 0.2, 1.5, 0.9, 2.0, 2.5])\n",
    "        draw = np.array([np.random.uniform(low=low, high=high) for _ in range(N)])\n",
    "        return sl.SampleStore(z_lens = torch.tensor(draw).float())\n",
    "    \n",
    "m = Model()\n",
    "m.sample(3);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2be2f92-d80e-4aa5-9844-302ce3ea11f6",
   "metadata": {},
   "source": [
    "## Definition of target image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe89a65c-22bf-4f02-995a-2e92ef0c41e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 36.89it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 14650.03it/s]\n"
     ]
    }
   ],
   "source": [
    "s_targets = m.sample(10)\n",
    "# torch.save(s_targets, \"test_targets_sersic.pt\")\n",
    "# s_targets = torch.load(\"test_targets_sersic.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "083b631d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k, v in s_targets.items():\n",
    "#     print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f626b7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for v in ['img', 'mu', 'X', 'Y' ,  'Xsrc', 'Ysrc']:\n",
    "#     print(v)\n",
    "#     plt_imshow(s_targets[v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe229806-1f9c-4c57-b649-8d98e065b6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "s0 = s_targets[6]\n",
    "# print(s0['z_lens'])\n",
    "# print(s0['z_src'])\n",
    "# plt.figure(figsize=(15, 5))\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.imshow(s0['img'].cpu())\n",
    "# plt.colorbar()\n",
    "# plt.subplot(1, 2, 2)\n",
    "sersic = SersicSource()\n",
    "# src = sersic(X=s0['X'].cpu(), Y=s0['Y'].cpu(), x=s0['z_src'][0].cpu(), y=s0['z_src'][1].cpu(), phi=s0['z_src'][2].cpu(), q=s0['z_src'][3].cpu(), index=s0['z_src'][4].cpu(), r_e=s0['z_src'][5].cpu(), I_e=s0['z_src'][6].cpu())\n",
    "# plt.imshow(src)\n",
    "# plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a07ed02e-2295-42ba-a71a-5de9812bdd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rec = lensing_model.deproject_idx(s0['img'].unsqueeze(0), s0['kNN_idx'].unsqueeze(0)).mean(axis=1).squeeze(0)\n",
    "# plt.imshow(rec)\n",
    "# plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0afb416-08aa-4499-8914-2b321d905f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LensNetwork(sl.SwyftModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.online_z_score = swyft.networks.OnlineDictStandardizingLayer(dict(img = (NPIX_IMG, NPIX_IMG)))\n",
    "        self.CNN = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 10, 3),\n",
    "            torch.nn.MaxPool2d(2),\n",
    "            torch.nn.Conv2d(10, 20, 3),\n",
    "            torch.nn.MaxPool2d(2),\n",
    "            torch.nn.Conv2d(20, 40, 3),\n",
    "            torch.nn.MaxPool2d(2),\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.LazyLinear(128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.LazyLinear(256),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(256, 16),\n",
    "        )\n",
    "        self.c = sl.RatioEstimatorMLP1d(16, 6, hidden_features = 256)\n",
    "        \n",
    "    def forward(self, x, z):\n",
    "        # Digesting x\n",
    "        x = dict(img = x['img'])\n",
    "        x = self.online_z_score(x)['img']\n",
    "#         print('going through LenseNetwork')\n",
    "        x = self.CNN(x.unsqueeze(1)).squeeze(1)\n",
    "        \n",
    "#         print('x', x.shape)\n",
    "#         print('z', z['z_lens'].shape)\n",
    "        \n",
    "        out = self.c(x, z['z_lens'])\n",
    "#         print('out', out)\n",
    "        return dict(z_lens = out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af8e0902-5093-43e7-8041-3d86084cf4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SourceNetwork(sl.SwyftModule):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.l = torch.nn.Linear(10, 10)\n",
    "#         self.reg1d = sl.RatioEstimatorGaussian1d(momentum = 0.1)\n",
    "#         self.L = torch.nn.Linear(NPIX_SRC**2, NPIX_SRC**2)\n",
    "        \n",
    "#     def get_img_rec(self, x):\n",
    "#         x_img = x['img']\n",
    "#         x_kNN_idx = x['kNN_idx']\n",
    "#         x_src_rec = lensing_model.deproject_idx(x_img, x_kNN_idx)[:,:,:,:].mean(dim=1)\n",
    "#         x_src_rec = self.L(x_src_rec.view(-1, NPIX_SRC*NPIX_SRC)).view(-1, NPIX_SRC, NPIX_SRC)*0 + x_src_rec\n",
    "#         return x_src_rec\n",
    "    \n",
    "#     def forward(self, x, z):\n",
    "#         x_img_rec = self.get_img_rec(x)\n",
    "#         z_src = z['z_src']\n",
    "#         x_img_rec, z_src = sl.equalize_tensors(x_img_rec, z_src)\n",
    "#         w = self.reg1d(x_img_rec, z_src)\n",
    "#         return dict(z_src = w)\n",
    "\n",
    "class SourceNetwork(sl.SwyftModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.online_z_score = swyft.networks.OnlineDictStandardizingLayer(dict(img = (NPIX_IMG, NPIX_IMG)))\n",
    "        self.CNN = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 10, 3),\n",
    "            torch.nn.MaxPool2d(2),\n",
    "            torch.nn.Conv2d(10, 20, 3),\n",
    "            torch.nn.MaxPool2d(2),\n",
    "            torch.nn.Conv2d(20, 40, 3),\n",
    "            torch.nn.MaxPool2d(2),\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.LazyLinear(128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.LazyLinear(256),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(256, 16),\n",
    "        )\n",
    "        self.c = sl.RatioEstimatorMLP1d(16, 7, hidden_features = 256)\n",
    "        \n",
    "    def forward(self, x, z):\n",
    "        # Digesting x\n",
    "        x = dict(img = x['img'])\n",
    "        x = self.online_z_score(x)['img']\n",
    "#         print('going through LensNetwork')\n",
    "        x = self.CNN(x.unsqueeze(1)).squeeze(1)\n",
    "        \n",
    "        out = self.c(x, z['z_src'])\n",
    "        return dict(z_src = out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39dac473-98a3-481e-b9af-b8d30157fda2",
   "metadata": {},
   "source": [
    "# Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f1e55ad-8e23-47e9-9bae-27d11c75a3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "s0_img = dict(img = s0['img'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb94e0a7-d80e-46d0-82fd-eeb6143b5b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ntrain1, R1, ME = 5000, 2, 3 # Number of training simulations, number of training rounds (?), max epochs \n",
    "Ntrain1, R1, ME = 50, 1, 2 # Number of training simulations, number of training rounds (?), max epochs \n",
    "TARGET = 3\n",
    "tag = 'VSersic01'\n",
    "INFER_SOURCE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4979837a-be5f-43ef-8a84-e4752a1c9228",
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Set SLURM handle signals.\n",
      "\n",
      "  | Name           | Type                         | Params\n",
      "----------------------------------------------------------------\n",
      "0 | online_z_score | OnlineDictStandardizingLayer | 0     \n",
      "1 | CNN            | Sequential                   | 13.3 K\n",
      "2 | c              | RatioEstimatorMLP1d          | 1.6 M \n",
      "----------------------------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.535     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3bdd43d3246480ba013f846bc2712be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc6fee4b8f05405c80e27d8710b08730",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'hp/JS-div': 8.318975448608398, 'hp/KL-div': 0.056465357542037964}\n",
      "--------------------------------------------------------------------------------\n",
      "printing self! <swyft.lightning.components.SwyftTrainer object at 0x148cf093d490> <bound method Trainer.predict of <swyft.lightning.components.SwyftTrainer object at 0x148cf093d490>>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e0f65a519804f3a9ffad99c3373cf56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Set SLURM handle signals.\n",
      "\n",
      "  | Name           | Type                         | Params\n",
      "----------------------------------------------------------------\n",
      "0 | online_z_score | OnlineDictStandardizingLayer | 0     \n",
      "1 | CNN            | Sequential                   | 13.3 K\n",
      "2 | c              | RatioEstimatorMLP1d          | 1.9 M \n",
      "----------------------------------------------------------------\n",
      "1.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 M     Total params\n",
      "7.615     Total estimated model params size (MB)\n",
      "/home/eliasd/.pyenv/versions/3.9.7/envs/lens-3.9.7/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:631: UserWarning: Checkpoint directory lightning_logs/lensing_VSersic01/version_3/checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e0c404c84774b8c8bef8c634832e056",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:02<00:00, 37.33it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 20971.52it/s]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing self! <swyft.lightning.components.SwyftTrainer object at 0x148cf06e6a00> <bound method Trainer.predict of <swyft.lightning.components.SwyftTrainer object at 0x148cf06e6a00>>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3014486dba9a4d77b472e6b4354515a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 3it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bounds = None\n",
    "results = []\n",
    "s0 = s_targets[TARGET]\n",
    "for i in range(R1):\n",
    "    tbl = pl_loggers.TensorBoardLogger(\"lightning_logs\", name = 'lensing_%s'%tag)#, default_hp_metric=True)\n",
    "    # s1: img, lens, src ~ p(img|lens, src)p(lens)p(src)\n",
    "    s1 = sl.file_cache(lambda: m.sample(Ntrain1, bounds = bounds), './train_data_%s_%i_%i_%i.pt'%(tag, TARGET, Ntrain1, i))\n",
    "    \n",
    "    # r1: p(z_lens|img)/p(z_lens)\n",
    "    r1 = LensNetwork()\n",
    "    \n",
    "    # d1: split img vs z_lens\n",
    "    # TODO: Specify x_keys = ['img'], z_keys=['z_lens']\n",
    "    d1 = sl.SwyftDataModule(store = s1, model = m, batch_size = 128)\n",
    "    \n",
    "    # Train r1 with d1\n",
    "    t1 = sl.SwyftTrainer(accelerator = 'gpu', gpus=1, max_epochs = ME, logger = tbl)\n",
    "    t1.fit(r1, d1)\n",
    "    t1.test(r1, d1)\n",
    "    \n",
    "    # p1: z_lens ~ p(z_lens|img_obs)  --  these are weighted samples\n",
    "    p1 = t1.infer(r1, d1, condition_x = s0)\n",
    "\n",
    "    if INFER_SOURCE:\n",
    "        # r2: p(src|z_lens, img)/p(src)\n",
    "        r2 = SourceNetwork()\n",
    "\n",
    "        # d2: split (img, kNN_idx) vs src\n",
    "        # TODO: Specify x_keys = ['img', 'kNN_idx'], z_keys=['src']\n",
    "        d2 = sl.SwyftDataModule(store = s1, model = m, batch_size = 16)\n",
    "\n",
    "        # Train r2 with d2\n",
    "        t2 = sl.SwyftTrainer(accelerator = 'gpu', gpus=1, max_epochs = 2, logger = tbl)\n",
    "        t2.fit(r2, d2)\n",
    "\n",
    "        # d3: img, lens, src ~ p(img|lens, src)p(lens|img_obs)\n",
    "        s3 = m.sample(100, bounds = bounds, effective_prior = {'z_lens': p1})\n",
    "\n",
    "        # d3: split (img, kNN) vs (z_lens, src)\n",
    "        # TODO: Specify x_keys = ['img', 'kNN_idx'], z_keys=['z_lens', 'src']\n",
    "        d3 = sl.SwyftDataModule(store = s3, model = m, batch_size = 16)\n",
    "\n",
    "        # ws2: src ~ p(src|img_obs) = \\int dlens p(src|lens, img_obs)*p(lens|img_obs)  --  weighted samples\n",
    "        p2 = t2.infer(r2, d3, condition_x = s0_img)\n",
    "\n",
    "        # Rectangle Bounds\n",
    "        all_inference = dict(**p1, **p2)\n",
    "    else:\n",
    "        all_inference = p1\n",
    "        p2 = None\n",
    "        \n",
    "    bounds = sl.get_1d_rect_bounds(all_inference, th = 1e-6)  # for p(z_lens)\n",
    "    #results.append(dict(bounds = bounds, t1=t1, t2=t2, d1=d1, ws1=ws1, ws2=ws2))\n",
    "    results.append(dict(p1=p1, p2=p2, bounds = bounds))\n",
    "    \n",
    "    # Making nice plots\n",
    "    \n",
    "    z = p1.sample(10000)['z_lens'].numpy()\n",
    "    zr = p1.sample(10000000, replacement = False)['z_lens'].numpy()\n",
    "    for k in range(6):\n",
    "        fig = plt.figure(dpi = 100)\n",
    "        plt.hist(zr[:,k], density = True, bins = 20, color = 'r')\n",
    "        plt.hist(z[:,k], density = True, bins = 20, color = 'b')\n",
    "        plt.axvline(s0['z_lens'][k], color='r')\n",
    "        tbl.experiment.add_figure(\"posterior/%i\"%k, fig)\n",
    "        \n",
    "    fig = plt.figure()\n",
    "    key = 'z_lens'\n",
    "    for k in range(6):\n",
    "        l, h = bounds[key].low[k], bounds[key].high[k]\n",
    "        plt.plot([k, k], [l, h], 'k')\n",
    "        plt.scatter(k, s0[key][k], marker='o', color='r')\n",
    "    tbl.experiment.add_figure(\"bounds\", fig)\n",
    "\n",
    "    for k in range(8):\n",
    "        fig = plt.figure()\n",
    "        img = s1[k]['img']\n",
    "        plt.imshow(img)\n",
    "        tbl.experiment.add_figure(\"train_data/%i\"%k, fig)\n",
    "        \n",
    "    for k in range(8):\n",
    "        fig = plt.figure()\n",
    "        img = sersic(X=s1[k]['X'].cpu(), Y=s1[k]['Y'].cpu(), x=s1[k]['z_src'][0].cpu(), y=s1[k]['z_src'][1].cpu(), phi=s1[k]['z_src'][2].cpu(), q=s1[k]['z_src'][3].cpu(), index=s1[k]['z_src'][4].cpu(), r_e=s1[k]['z_src'][5].cpu(), I_e=s1[k]['z_src'][6].cpu())\n",
    "        plt.imshow(img)\n",
    "        tbl.experiment.add_figure(\"train_data_src/%i\"%k, fig)\n",
    "        \n",
    "    fig = plt.figure()\n",
    "    plt.imshow(s0['img'])\n",
    "    tbl.experiment.add_figure(\"target/image\", fig)\n",
    "    fig = plt.figure()\n",
    "    src = sersic(X=s0['X'].cpu(), Y=s0['Y'].cpu(), x=s0['z_src'][0].cpu(), y=s0['z_src'][1].cpu(), phi=s0['z_src'][2].cpu(), q=s0['z_src'][3].cpu(), index=s0['z_src'][4].cpu(), r_e=s0['z_src'][5].cpu(), I_e=s0['z_src'][6].cpu())\n",
    "    plt.imshow(src)\n",
    "    tbl.experiment.add_figure(\"target/source\", fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd08459-ce91-40bd-bb73-2170d6ee9f7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
