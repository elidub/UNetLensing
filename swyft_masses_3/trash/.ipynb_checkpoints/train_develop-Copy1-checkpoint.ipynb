{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a1da19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "\n",
    "import os, datetime\n",
    "import torch, pyro, numpy as np\n",
    "torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "\n",
    "import swyft\n",
    "import click\n",
    "\n",
    "\n",
    "DEVICE = 'cuda'\n",
    "\n",
    "from utils import *\n",
    "# from network import CustomTail, CustomHead\n",
    "\n",
    "from swyft.utils import tensor_to_array, array_to_tensor\n",
    "from toolz import compose\n",
    "from pyrofit.lensing.distributions import get_default_shmf\n",
    "\n",
    "import torch, numpy as np\n",
    "torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "from torch import tensor\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "\n",
    "# @click.command()\n",
    "# @click.option(\"--m\",    type=int, default = 12,  help=\"Exponent of subhalo mass.\")\n",
    "# @click.option(\"--nsub\", type=int, default = 1,   help=\"Number of subhaloes.\")\n",
    "# @click.option(\"--nsim\", type=int, default = 100, help=\"Number of simulations to run.\")\n",
    "\n",
    "# @click.option(\"--nmbins\",  type=int, default = 2,   help=\"Number of mass bins.\")\n",
    "\n",
    "# @click.option(\"--lr\",         type=float, default = 1e-3, help=\"Learning rate.\")\n",
    "# @click.option(\"--factor\",     type=float, default = 1e-1, help = \"Factor of Scheduler\")\n",
    "# @click.option(\"--patience\",   type=int,   default = 5,    help = \"Patience of Scheduler\")\n",
    "# @click.option(\"--max_epochs\", type=int,   default = 30,   help = \"Max number of epochs.\")\n",
    "\n",
    "\n",
    "\n",
    "m = 0\n",
    "nsub = 3\n",
    "nsim = 200\n",
    "\n",
    "nmbins = 2\n",
    "\n",
    "lr = 1e-3\n",
    "factor = 1e-1\n",
    "patience = 5\n",
    "max_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fb9aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = datetime.datetime.now()\n",
    "\n",
    "# Set definitions (should go to click)\n",
    "system_name = \"ngc4414\"\n",
    "\n",
    "# Set utilities\n",
    "sim_name, sim_path = get_sim_path(m, nsub, nsim, system_name)\n",
    "store = swyft.Store.load(path=sim_path)\n",
    "print(f'Store has {len(store)} simulations.')\n",
    "\n",
    "torch.set_default_tensor_type(torch.cuda.FloatTensor)  # HACK\n",
    "CONFIG = get_config(system_name, str(nsub), str(m))\n",
    "torch.set_default_tensor_type(torch.FloatTensor)\n",
    "\n",
    "prior, n_pars, lows, highs = get_prior(CONFIG)\n",
    "L = CONFIG.kwargs[\"defs\"][\"nx\"]\n",
    "print(f'Image has L = {L}.')\n",
    "\n",
    "# Set up posterior\n",
    "torch.set_default_tensor_type(torch.FloatTensor)\n",
    "dataset = swyft.Dataset(nsim, prior, store)#, simhook = noise)\n",
    "# marginals = [i for i in range(L**2)]\n",
    "# post = swyft.Posteriors(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929f93b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "post_name, post_path = get_post_path(sim_name, nmbins, lr, factor, patience)\n",
    "print(f'Training {post_name}!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f53df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mapping:\n",
    "    def __init__(self, nmbins, L, lows, highs):\n",
    "        self.nmbins = nmbins\n",
    "        self.L   = L\n",
    "        self.lows = lows\n",
    "        self.highs = highs\n",
    "\n",
    "    def coord_vu(self, coords_v):\n",
    "                        \n",
    "        n = len(coords_v[0])/3\n",
    "        assert n.is_integer()\n",
    "        n = int(n)\n",
    "\n",
    "        lows = np.full(coords_v.shape, np.tile(self.lows, n))\n",
    "        highs = np.full(coords_v.shape, np.tile(self.highs, n))   \n",
    "                \n",
    "        u = lambda v: (v - lows) / (highs - lows)\n",
    "        coords_u = u(coords_v)\n",
    "        return coords_u\n",
    "\n",
    "    def coord_to_map(self, XY_u):\n",
    "\n",
    "        \n",
    "        n_batch =  XY_u.shape[0]\n",
    "        n_coords = XY_u.shape[1]*2/3\n",
    "        assert n_coords.is_integer()\n",
    "\n",
    "        z = torch.zeros((n_batch, self.nmbins + 1, self.L, self.L), device = DEVICE)\n",
    "                \n",
    "        if not (n_batch == 0 or n_coords == 0):\n",
    "            \n",
    "            x_sub_u, y_sub_u, log10_m_sub_u = XY_u.view(-1,3).T.to(DEVICE)\n",
    "\n",
    "            x_i = torch.floor((x_sub_u*self.L).flatten()).type(torch.long) \n",
    "            y_i = torch.floor((y_sub_u*self.L).flatten()).type(torch.long) \n",
    "            m_i = torch.floor( log10_m_sub_u * self.nmbins ).type(torch.long) + 1\n",
    "            \n",
    "            i   = torch.floor(torch.arange(0, n_batch, 1/n_coords*2).to(DEVICE)).type(torch.long)\n",
    "            xx = tuple(torch.stack((i, m_i, y_i, x_i)))\n",
    "            z[xx] = 1\n",
    "\n",
    "            xx = tuple(torch.stack((i, torch.zeros_like(m_i), y_i, x_i)))\n",
    "            z[xx] = 1\n",
    "            \n",
    "        z[:,0] = 1 - z[:,0]\n",
    "\n",
    "        return z\n",
    "\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, 1, 1, bias=False), # bias = False becaise BatchNorm2d is set\n",
    "            nn.BatchNorm2d(out_channels), # BatchNorm2d were not known when paper came out\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNET(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, features = [64, 128, 256, 512]):\n",
    "        super(UNET, self).__init__()\n",
    "                \n",
    "        self.ups = nn.ModuleList()\n",
    "        self.downs = nn.ModuleList()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2) # keep size the same\n",
    "        \n",
    "\n",
    "        # Down part of UNET\n",
    "        for feature in features:\n",
    "            self.downs.append(DoubleConv(in_channels, feature))\n",
    "            in_channels = feature\n",
    "\n",
    "        # Up part of UNET\n",
    "        for feature in reversed(features):\n",
    "            self.ups.append(\n",
    "                nn.ConvTranspose2d(\n",
    "                    feature*2, feature, kernel_size=2, stride=2,\n",
    "                )\n",
    "            )\n",
    "            self.ups.append(DoubleConv(feature*2, feature))\n",
    "\n",
    "        self.bottleneck = DoubleConv(features[-1], features[-1]*2)\n",
    "        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
    "        \n",
    "\n",
    "    def forward(self, x, target):\n",
    "                \n",
    "        x = x.unsqueeze(1)\n",
    "        skip_connections = []\n",
    "\n",
    "        for down in self.downs:\n",
    "            x = down(x)\n",
    "            skip_connections.append(x)\n",
    "            x = self.pool(x)\n",
    "\n",
    "        x = self.bottleneck(x)\n",
    "        skip_connections = skip_connections[::-1] # reverse list\n",
    "\n",
    "        # the upsampling\n",
    "        for idx in range(0, len(self.ups), 2): # step of 2 because we want up - double column - up - double column\n",
    "            x = self.ups[idx](x)\n",
    "            skip_connection = skip_connections[idx//2] # //2 because we want still steps of one\n",
    "\n",
    "            # if statement because we can put in shapes that are not divisble by two around 19:00 of video\n",
    "            if x.shape != skip_connection.shape: \n",
    "                x = TF.resize(x, size=skip_connection.shape[2:]) # hopefully does not impact accuracy too much\n",
    "\n",
    "            concat_skip = torch.cat((skip_connection, x), dim=1)\n",
    "            x = self.ups[idx+1](concat_skip)\n",
    "\n",
    "        x = self.final_conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572ef479",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "class CustomHead(swyft.Module):\n",
    "    def __init__(self, obs_shapes) -> None:\n",
    "        super().__init__(obs_shapes=obs_shapes)\n",
    "        self.n_features = torch.prod(tensor(obs_shapes['image']))\n",
    "#         self.onl_norm = OnlineNormalizationLayer(torch.Size([self.n_features]))\n",
    "\n",
    "    def forward(self, obs) -> torch.Tensor:\n",
    "        x = obs[\"image\"]\n",
    "        n_batch = len(x)\n",
    "        x = x.view(n_batch, self.n_features)\n",
    "#         x = self.onl_norm(x)    \n",
    "        return x\n",
    "\n",
    "\n",
    "class CustomTail(swyft.Module):\n",
    "    def __init__(self, n_features, marginals, **tail_args):\n",
    "        super().__init__(n_features = n_features, marginals = marginals, **tail_args)\n",
    "        \n",
    "        \n",
    "        self.n_features = n_features\n",
    "        self.L = int(np.sqrt(n_features).item())\n",
    "        self.nmbins = tail_args['nmbins']\n",
    "        self.lows   = tail_args['lows']\n",
    "        self.highs  = tail_args['highs']\n",
    "        self.out_channels = self.nmbins + 1\n",
    "        \n",
    "        self.Map  = Mapping(self.nmbins, self.L, self.lows, self.highs)\n",
    "        self.UNet = UNET(in_channels = 1, out_channels = self.out_channels)\n",
    "        \n",
    "       \n",
    "    def forward(self, sims, target):\n",
    "        \n",
    "        sims = sims.view(-1, self.L, self.L)\n",
    "        \n",
    "        x = self.UNet(sims, target)\n",
    "        z = self.Map.coord_to_map(target)\n",
    "        \n",
    "        x = x * z\n",
    "        x = x.view(-1, self.n_features * self.out_channels)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031c1a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_tensor_type(torch.FloatTensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504cddc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomHead(swyft.Module):\n",
    "    def __init__(self, obs_shapes) -> None:\n",
    "        super().__init__(obs_shapes=obs_shapes)\n",
    "        self.n_features = torch.prod(tensor(obs_shapes['image']))\n",
    "#         self.onl_norm = OnlineNormalizationLayer(torch.Size([self.n_features]))\n",
    "\n",
    "    def forward(self, obs) -> torch.Tensor:\n",
    "        x = obs[\"image\"]\n",
    "        n_batch = len(x)\n",
    "        x = x.view(n_batch, self.n_features)\n",
    "#         x = self.onl_norm(x)    \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1483daf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5232c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264c7945",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mapping:\n",
    "    def __init__(self, nmbins, L, lows, highs):\n",
    "        self.nmbins = nmbins\n",
    "        self.L   = L\n",
    "        self.lows = lows\n",
    "        self.highs = highs\n",
    "\n",
    "    def coord_vu(self, coords_v):\n",
    "                        \n",
    "        n = len(coords_v[0])/3\n",
    "        assert n.is_integer()\n",
    "        n = int(n)\n",
    "\n",
    "        lows = np.full(coords_v.shape, np.tile(self.lows, n))\n",
    "        highs = np.full(coords_v.shape, np.tile(self.highs, n))   \n",
    "                \n",
    "        u = lambda v: (v - lows) / (highs - lows)\n",
    "        coords_u = u(coords_v)\n",
    "        return coords_u\n",
    "\n",
    "    def coord_to_map(self, XY_u):\n",
    "        \n",
    "        assert 1 == 2\n",
    "\n",
    "        \n",
    "        n_batch =  XY_u.shape[0]\n",
    "        n_coords = XY_u.shape[1]*2/3\n",
    "        assert n_coords.is_integer()\n",
    "\n",
    "        z = torch.zeros((n_batch, self.nmbins + 1, self.L, self.L), device = DEVICE)\n",
    "                \n",
    "        if not (n_batch == 0 or n_coords == 0):\n",
    "            \n",
    "            x_sub_u, y_sub_u, log10_m_sub_u = XY_u.view(-1,3).T.to(DEVICE)\n",
    "\n",
    "            x_i = torch.floor((x_sub_u*self.L).flatten()).type(torch.long) \n",
    "            y_i = torch.floor((y_sub_u*self.L).flatten()).type(torch.long) \n",
    "            m_i = torch.floor( log10_m_sub_u * self.nmbins ).type(torch.long) + 1\n",
    "            \n",
    "            i   = torch.floor(torch.arange(0, n_batch, 1/n_coords*2).to(DEVICE)).type(torch.long)\n",
    "            xx = tuple(torch.stack((i, m_i, y_i, x_i)))\n",
    "            z[xx] = 1\n",
    "\n",
    "            xx = tuple(torch.stack((i, torch.zeros_like(m_i), y_i, x_i)))\n",
    "            z[xx] = 1\n",
    "            \n",
    "        z[:,0] = 1 - z[:,0]\n",
    "\n",
    "        return z\n",
    "\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, 1, 1, bias=False), # bias = False becaise BatchNorm2d is set\n",
    "            nn.BatchNorm2d(out_channels), # BatchNorm2d were not known when paper came out\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNET(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, features = [64, 128, 256, 512]):\n",
    "        super(UNET, self).__init__()\n",
    "                \n",
    "        self.ups = nn.ModuleList()\n",
    "        self.downs = nn.ModuleList()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2) # keep size the same\n",
    "        \n",
    "\n",
    "        # Down part of UNET\n",
    "        for feature in features:\n",
    "            self.downs.append(DoubleConv(in_channels, feature))\n",
    "            in_channels = feature\n",
    "\n",
    "        # Up part of UNET\n",
    "        for feature in reversed(features):\n",
    "            self.ups.append(\n",
    "                nn.ConvTranspose2d(\n",
    "                    feature*2, feature, kernel_size=2, stride=2,\n",
    "                )\n",
    "            )\n",
    "            self.ups.append(DoubleConv(feature*2, feature))\n",
    "\n",
    "        self.bottleneck = DoubleConv(features[-1], features[-1]*2)\n",
    "        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
    "        \n",
    "\n",
    "    def forward(self, x, target):\n",
    "                \n",
    "        x = x.unsqueeze(1)\n",
    "        skip_connections = []\n",
    "\n",
    "        for down in self.downs:\n",
    "            x = down(x)\n",
    "            skip_connections.append(x)\n",
    "            x = self.pool(x)\n",
    "\n",
    "        x = self.bottleneck(x)\n",
    "        skip_connections = skip_connections[::-1] # reverse list\n",
    "\n",
    "        # the upsampling\n",
    "        for idx in range(0, len(self.ups), 2): # step of 2 because we want up - double column - up - double column\n",
    "            x = self.ups[idx](x)\n",
    "            skip_connection = skip_connections[idx//2] # //2 because we want still steps of one\n",
    "\n",
    "            # if statement because we can put in shapes that are not divisble by two around 19:00 of video\n",
    "            if x.shape != skip_connection.shape: \n",
    "                x = TF.resize(x, size=skip_connection.shape[2:]) # hopefully does not impact accuracy too much\n",
    "\n",
    "            concat_skip = torch.cat((skip_connection, x), dim=1)\n",
    "            x = self.ups[idx+1](concat_skip)\n",
    "\n",
    "        x = self.final_conv(x)\n",
    "        return x\n",
    "\n",
    "class CustomObservationTransform(torch.nn.Module):\n",
    "    def __init__(self, observation_key: str, observation_shapes: dict):\n",
    "        super().__init__()\n",
    "        self.observation_key = observation_key\n",
    "        self.n_features = torch.prod(tensor(observation_shapes[observation_key]))\n",
    "#         self.online_z_score = swyft.networks.OnlineDictStandardizingLayer(observation_shapes)\n",
    "\n",
    "\n",
    "    def forward(self, obs: dict) -> torch.Tensor:      \n",
    "        x = obs\n",
    "#         x = self.online_z_score(obs)\n",
    "        x = x[self.observation_key]\n",
    "        x = x.view(len(x), self.n_features)\n",
    "        print(x)\n",
    "        return x\n",
    "    \n",
    "class CustomTail(nn.Module):\n",
    "    def __init__(self, n_features, marginals, **tail_args):\n",
    "        super().__init__(n_features = n_features, marginals = marginals, **tail_args)\n",
    "        \n",
    "        \n",
    "        self.n_features = n_features\n",
    "        self.L = int(np.sqrt(n_features).item())\n",
    "        self.nmbins = tail_args['nmbins']\n",
    "        self.lows   = tail_args['lows']\n",
    "        self.highs  = tail_args['highs']\n",
    "        self.out_channels = self.nmbins + 1\n",
    "        \n",
    "        self.Map  = Mapping(self.nmbins, self.L, self.lows, self.highs)\n",
    "        self.UNet = UNET(in_channels = 1, out_channels = self.out_channels)\n",
    "        \n",
    "       \n",
    "    def forward(self, sims, target):\n",
    "        \n",
    "        sims = sims.view(-1, self.L, self.L)\n",
    "        \n",
    "        x = self.UNet(sims, target)\n",
    "        z = self.Map.coord_to_map(target)\n",
    "        \n",
    "        x = x * z\n",
    "        x = x.view(-1, self.n_features * self.out_channels)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class CustomMarginalClassifier(torch.nn.Module):\n",
    "    def __init__(self, n_marginals: int, n_combined_features: int):\n",
    "        super().__init__()\n",
    "        self.n_marginals = n_marginals\n",
    "        self.n_combined_features = n_combined_features\n",
    "        \n",
    "        self.n_features = 1600 #n_features\n",
    "        self.L = int(np.sqrt(self.n_features).item())\n",
    "        self.nmbins = 2 #tail_args['nmbins']\n",
    "        self.lows   = lows #tail_args['lows']\n",
    "        self.highs  = highs #tail_args['highs']\n",
    "        self.out_channels = self.nmbins + 1\n",
    "        \n",
    "        self.Map  = Mapping(self.nmbins, self.L, self.lows, self.highs)\n",
    "        self.UNet = UNET(in_channels = 1, out_channels = self.out_channels)\n",
    "        \n",
    "    def forward(self, sims, target):\n",
    "        \n",
    "        sims = sims.view(-1, self.L, self.L)\n",
    "        \n",
    "        x = self.UNet(sims, target)\n",
    "        z = self.Map.coord_to_map(target)\n",
    "        \n",
    "        x = x * z\n",
    "        x = x.view(-1, self.n_features * self.out_channels)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def forward(\n",
    "        self, features: torch.Tensor, marginal_block: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        sims = features\n",
    "        target = marginal_block\n",
    "        \n",
    "        x = self.UNet(sims, target)\n",
    "        z = self.Map.coord_to_map(target)\n",
    "        \n",
    "        x = x * z\n",
    "        x = x.view(-1, self.n_features * self.out_channels)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "        \n",
    "#         fb = features.unsqueeze(1).expand(-1, self.n_marginals, -1)  # B, M, O\n",
    "#         combined = torch.cat([fb, marginal_block], dim=2)  # B, M, O + P\n",
    "#         return self.net(combined).squeeze(-1)  # B, M\n",
    "        \n",
    "        \n",
    "        \n",
    "#         print(n_marginals, n_combined_features)\n",
    "\n",
    "# class CustomMarginalClassifier(torch.nn.Module):\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         n_marginals: int,\n",
    "#         n_combined_features: int,\n",
    "#         hidden_features: int,\n",
    "#         num_blocks=2,\n",
    "#     ) -> None:\n",
    "#         super().__init__()\n",
    "#         self.n_marginals = n_marginals\n",
    "#         self.n_combined_features = n_combined_features\n",
    "\n",
    "#         blocks = [\n",
    "#             LinearWithChannel(self.n_marginals, self.n_combined_features, hidden_features),\n",
    "#             torch.nn.ReLU(),\n",
    "#             BatchNorm1dWithChannel(self.n_marginals, hidden_features),\n",
    "#         ]\n",
    "#         for _ in range(num_blocks - 1):\n",
    "#             blocks.append(LinearWithChannel(self.n_marginals, hidden_features, hidden_features))\n",
    "#             blocks.append(torch.nn.ReLU())\n",
    "#             blocks.append(BatchNorm1dWithChannel(self.n_marginals, hidden_features))\n",
    "\n",
    "#         self.net = torch.nn.Sequential(\n",
    "#             *blocks,\n",
    "#             LinearWithChannel(self.n_marginals, hidden_features, 1)\n",
    "#         )\n",
    "\n",
    "#     def forward(\n",
    "#         self, features: torch.Tensor, marginal_block: torch.Tensor\n",
    "#     ) -> torch.Tensor:\n",
    "#         fb = features.unsqueeze(1).expand(-1, self.n_marginals, -1)  # B, M, O\n",
    "#         combined = torch.cat([fb, marginal_block], dim=2)  # B, M, O + P\n",
    "#         return self.net(combined).squeeze(-1)  # B, M\n",
    "\n",
    "    \n",
    "def get_custom_marginal_classifier(\n",
    "    observation_transform,\n",
    "    marginal_indices: tuple,\n",
    "    n_parameters: int,\n",
    "    marginal_classifier,\n",
    "    parameter_online_z_score: bool = False\n",
    ") -> torch.nn.Module:\n",
    "    n_observation_features = observation_transform.n_features\n",
    "\n",
    "    parameter_transform = swyft.networks.ParameterTransform(\n",
    "        n_parameters, marginal_indices, online_z_score=parameter_online_z_score\n",
    "    )\n",
    "    \n",
    "    n_marginals, n_block_parameters = parameter_transform.marginal_block_shape\n",
    "\n",
    "    marginal_classifier = marginal_classifier(\n",
    "        n_marginals,\n",
    "        n_observation_features + n_block_parameters,\n",
    "    )\n",
    "\n",
    "    return swyft.networks.Network(\n",
    "        observation_transform,\n",
    "        parameter_transform,\n",
    "        marginal_classifier,\n",
    "    )\n",
    "    \n",
    "\n",
    "observation_key = 'image'\n",
    "marginal_indices = [i for i in range(L**2)]\n",
    "observation_shapes = {\"image\": (L, L)}\n",
    "n_parameters = n_pars\n",
    "\n",
    "observation_transform = CustomObservationTransform(observation_key, observation_shapes)\n",
    "marginal_classifier = CustomMarginalClassifier\n",
    "    \n",
    "network = get_custom_marginal_classifier(\n",
    "    observation_transform = observation_transform,\n",
    "    marginal_indices = marginal_indices,\n",
    "#     observation_shapes = observation_shapes,\n",
    "    n_parameters= n_parameters,\n",
    "    marginal_classifier = marginal_classifier)\n",
    "\n",
    "mre = swyft.MarginalRatioEstimator(\n",
    "    marginal_indices = marginal_indices,\n",
    "    network = network,\n",
    "    device = DEVICE,\n",
    ")\n",
    "\n",
    "mre.train(dataset, max_epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa186b56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623f9349",
   "metadata": {},
   "outputs": [],
   "source": [
    "swyft.Posterios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4423571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "post_name, post_path = get_post_path(sim_name, nmbins, lr, factor, patience)\n",
    "print(f'Training {post_name}!')\n",
    "\n",
    "torch.set_default_tensor_type(torch.FloatTensor)\n",
    "post = swyft.Posteriors(dataset)\n",
    "post.add(marginals, device = DEVICE, \n",
    "         tail_args = dict(nmbins = nmbins, lows = lows, highs = highs),\n",
    "         head = CustomHead, tail = CustomTail)\n",
    "post.train(marginals, max_epochs = max_epochs,\n",
    "           optimizer_args = dict(lr=lr),\n",
    "           scheduler_args = dict(factor = factor, patience = patience)\n",
    "          )\n",
    "post.save(post_path)\n",
    "\n",
    "print('Done!')\n",
    "print(f\"Total training time is {str(datetime.datetime.now() - time_start).split('.')[0]}!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
