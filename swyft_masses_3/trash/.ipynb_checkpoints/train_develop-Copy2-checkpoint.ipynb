{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb57520",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "\n",
    "import os, datetime\n",
    "import torch, pyro, numpy as np\n",
    "torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "\n",
    "import swyft\n",
    "import click\n",
    "\n",
    "\n",
    "DEVICE = 'cuda'\n",
    "\n",
    "from utils import *\n",
    "# from network import CustomTail, CustomHead\n",
    "\n",
    "from swyft.utils import tensor_to_array, array_to_tensor\n",
    "from toolz import compose\n",
    "from pyrofit.lensing.distributions import get_default_shmf\n",
    "\n",
    "import torch, numpy as np\n",
    "torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "from torch import tensor\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "\n",
    "# @click.command()\n",
    "# @click.option(\"--m\",    type=int, default = 12,  help=\"Exponent of subhalo mass.\")\n",
    "# @click.option(\"--nsub\", type=int, default = 1,   help=\"Number of subhaloes.\")\n",
    "# @click.option(\"--nsim\", type=int, default = 100, help=\"Number of simulations to run.\")\n",
    "\n",
    "# @click.option(\"--nmbins\",  type=int, default = 2,   help=\"Number of mass bins.\")\n",
    "\n",
    "# @click.option(\"--lr\",         type=float, default = 1e-3, help=\"Learning rate.\")\n",
    "# @click.option(\"--factor\",     type=float, default = 1e-1, help = \"Factor of Scheduler\")\n",
    "# @click.option(\"--patience\",   type=int,   default = 5,    help = \"Patience of Scheduler\")\n",
    "# @click.option(\"--max_epochs\", type=int,   default = 30,   help = \"Max number of epochs.\")\n",
    "\n",
    "\n",
    "\n",
    "m = 0\n",
    "nsub = 3\n",
    "nsim = 200\n",
    "\n",
    "nmbins = 2\n",
    "\n",
    "lr = 1e-3\n",
    "factor = 1e-1\n",
    "patience = 5\n",
    "max_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81f655cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Store _M_m0_nsub3_nsim200 exists!\n",
      "Loading existing store.\n",
      "Store has 208 simulations.\n",
      "Image has L = 40.\n"
     ]
    }
   ],
   "source": [
    "time_start = datetime.datetime.now()\n",
    "\n",
    "# Set definitions (should go to click)\n",
    "system_name = \"ngc4414\"\n",
    "\n",
    "# Set utilities\n",
    "sim_name, sim_path = get_sim_path(m, nsub, nsim, system_name)\n",
    "store = swyft.Store.load(path=sim_path)\n",
    "print(f'Store has {len(store)} simulations.')\n",
    "\n",
    "torch.set_default_tensor_type(torch.cuda.FloatTensor)  # HACK\n",
    "CONFIG = get_config(system_name, str(nsub), str(m))\n",
    "torch.set_default_tensor_type(torch.FloatTensor)\n",
    "\n",
    "prior, n_pars, lows, highs = get_prior(CONFIG)\n",
    "L = CONFIG.kwargs[\"defs\"][\"nx\"]\n",
    "print(f'Image has L = {L}.')\n",
    "\n",
    "# Set up posterior\n",
    "torch.set_default_tensor_type(torch.FloatTensor)\n",
    "dataset = swyft.Dataset(nsim, prior, store)#, simhook = noise)\n",
    "# marginals = [i for i in range(L**2)]\n",
    "# post = swyft.Posteriors(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06006684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training UNet_M_m0_nsub3_nsim200_nmbins2_lr-3.0_fac-1.0_pat5.pt!\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "post_name, post_path = get_post_path(sim_name, nmbins, lr, factor, patience)\n",
    "print(f'Training {post_name}!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1babcb4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.3333, 0.6667, 1.0000, 1.3333, 1.6667, 2.0000, 2.3333, 2.6667,\n",
       "        3.0000, 3.3333, 3.6667, 4.0000, 4.3333, 4.6667, 5.0000, 5.3333, 5.6667,\n",
       "        6.0000, 6.3333, 6.6667, 7.0000, 7.3333, 7.6667, 8.0000, 8.3333, 8.6667,\n",
       "        9.0000, 9.3333, 9.6667])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(0, 10, 1/(9*2/3)*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "748b6446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 1., 1., 1., 2., 2., 2., 3., 3., 3., 4., 4., 4., 5., 5., 5.,\n",
       "        6., 6., 6., 7., 7., 7., 8., 8., 8., 9., 9., 9.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.floor(torch.arange(0, 10, 1/(9*2/3)*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2ca37fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "zeros, ones = torch.zeros((4, 2, 3, 3)), torch.ones((4, 2, 3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b19ce331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4, 3, 3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((zeros, ones), dim = 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a27907e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: lr=0.0005, epoch=10, validation loss=8873\n"
     ]
    }
   ],
   "source": [
    "class Mapping:\n",
    "    def __init__(self, nmbins, L, lows, highs):\n",
    "        self.nmbins = nmbins\n",
    "        self.L   = L\n",
    "        self.lows = lows\n",
    "        self.highs = highs\n",
    "\n",
    "    def coord_vu(self, coords_v):\n",
    "        \n",
    "        coords_v = coords_v.squeeze()\n",
    "      \n",
    "        n = len(coords_v[0])/3\n",
    "        assert n.is_integer()\n",
    "        n = int(n)\n",
    "        \n",
    "        lows = np.full(coords_v.shape, np.tile(self.lows, n))\n",
    "        highs = np.full(coords_v.shape, np.tile(self.highs, n))   \n",
    "                \n",
    "        u = lambda v: (v - lows) / (highs - lows)\n",
    "        coords_u = u(coords_v)\n",
    "        return coords_u\n",
    "\n",
    "    def coord_to_map(self, XY_v):\n",
    "        \n",
    "                \n",
    "        XY_u = self.coord_vu(XY_v)\n",
    "\n",
    "        n_batch =  XY_u.shape[0]\n",
    "        n_coords = XY_u.shape[1]*2/3\n",
    "        assert n_coords.is_integer()\n",
    "\n",
    "        z0 = torch.ones((n_batch, self.nmbins, self.L, self.L), device = DEVICE)\n",
    "        z1 = torch.zeros((n_batch, self.nmbins, self.L, self.L), device = DEVICE)\n",
    "                \n",
    "        if not (n_batch == 0 or n_coords == 0):\n",
    "            \n",
    "            x_sub_u, y_sub_u, log10_m_sub_u = XY_u.view(-1,3).T.to(DEVICE)\n",
    "\n",
    "            x_i = torch.floor((x_sub_u*self.L).flatten()).type(torch.long) \n",
    "            y_i = torch.floor((y_sub_u*self.L).flatten()).type(torch.long) \n",
    "            m_i = torch.floor( log10_m_sub_u * self.nmbins).type(torch.long) \n",
    "            b_i   = torch.floor(torch.arange(0, n_batch, 1/n_coords*2).to(DEVICE)).type(torch.long)\n",
    "            \n",
    "            indices = tuple(torch.stack((b_i, m_i, y_i, x_i)))\n",
    "            z0[indices], z1[indices] = 0, 1\n",
    "\n",
    "        return torch.cat((z0, z1), dim = 1)\n",
    "\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, 1, 1, bias=False), # bias = False becaise BatchNorm2d is set\n",
    "            nn.BatchNorm2d(out_channels), # BatchNorm2d were not known when paper came out\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNET(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, features = [64, 128, 256, 512]):\n",
    "        super(UNET, self).__init__()\n",
    "                \n",
    "        self.ups = nn.ModuleList()\n",
    "        self.downs = nn.ModuleList()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2) # keep size the same\n",
    "        \n",
    "\n",
    "        # Down part of UNET\n",
    "        for feature in features:\n",
    "            self.downs.append(DoubleConv(in_channels, feature))\n",
    "            in_channels = feature\n",
    "\n",
    "        # Up part of UNET\n",
    "        for feature in reversed(features):\n",
    "            self.ups.append(\n",
    "                nn.ConvTranspose2d(\n",
    "                    feature*2, feature, kernel_size=2, stride=2,\n",
    "                )\n",
    "            )\n",
    "            self.ups.append(DoubleConv(feature*2, feature))\n",
    "\n",
    "        self.bottleneck = DoubleConv(features[-1], features[-1]*2)\n",
    "        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "                \n",
    "        x = x.unsqueeze(1)\n",
    "        skip_connections = []\n",
    "\n",
    "        for down in self.downs:\n",
    "            x = down(x)\n",
    "            skip_connections.append(x)\n",
    "            x = self.pool(x)\n",
    "\n",
    "        x = self.bottleneck(x)\n",
    "        skip_connections = skip_connections[::-1] # reverse list\n",
    "\n",
    "        # the upsampling\n",
    "        for idx in range(0, len(self.ups), 2): # step of 2 because we want up - double column - up - double column\n",
    "            x = self.ups[idx](x)\n",
    "            skip_connection = skip_connections[idx//2] # //2 because we want still steps of one\n",
    "\n",
    "            # if statement because we can put in shapes that are not divisble by two around 19:00 of video\n",
    "            if x.shape != skip_connection.shape: \n",
    "                x = TF.resize(x, size=skip_connection.shape[2:]) # hopefully does not impact accuracy too much\n",
    "\n",
    "            concat_skip = torch.cat((skip_connection, x), dim=1)\n",
    "            x = self.ups[idx+1](concat_skip)\n",
    "\n",
    "        x = self.final_conv(x)\n",
    "        return x\n",
    "\n",
    "class CustomObservationTransform(torch.nn.Module):\n",
    "    def __init__(self, observation_key: str, observation_shapes: dict):\n",
    "        super().__init__()\n",
    "        self.observation_key = observation_key\n",
    "        self.n_features = torch.prod(tensor(observation_shapes[observation_key]))\n",
    "\n",
    "    def forward(self, obs: dict) -> torch.Tensor:      \n",
    "        x = obs\n",
    "        x = x[self.observation_key]\n",
    "        x = x.view(len(x), self.n_features)\n",
    "        return x\n",
    "\n",
    "class CustomMarginalClassifier(torch.nn.Module):\n",
    "    def __init__(self, n_marginals: int, n_combined_features: int):\n",
    "        super().__init__()\n",
    "                \n",
    "        self.n_marginals = n_marginals\n",
    "        self.n_combined_features = n_combined_features\n",
    "        \n",
    "        self.n_features = 1600 #n_features\n",
    "        self.L = int(np.sqrt(self.n_features).item())\n",
    "        self.nmbins = 2 #tail_args['nmbins']\n",
    "        self.lows   = lows #tail_args['lows']\n",
    "        self.highs  = highs #tail_args['highs']\n",
    "        self.out_channels = self.nmbins * 2\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.Map  = Mapping(self.nmbins, self.L, self.lows, self.highs)\n",
    "        self.UNet = UNET(in_channels = 1, out_channels = self.out_channels)\n",
    "        \n",
    "    def forward(\n",
    "        self, features: torch.Tensor, marginal_block: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        sims = features\n",
    "        target = marginal_block\n",
    "            \n",
    "    \n",
    "        sims = sims.view(-1, self.L, self.L)\n",
    "        x = self.UNet(sims)\n",
    "        z = self.Map.coord_to_map(target)\n",
    "        \n",
    "        x = x * z\n",
    "        x = x.view(-1, self.n_features * self.out_channels)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    \n",
    "def get_custom_marginal_classifier(\n",
    "    observation_transform,\n",
    "    marginal_indices: tuple,\n",
    "    n_parameters: int,\n",
    "    marginal_classifier,\n",
    "    parameter_online_z_score: bool = False\n",
    ") -> torch.nn.Module:\n",
    "    n_observation_features = observation_transform.n_features\n",
    "    \n",
    "    \n",
    "\n",
    "    parameter_transform = swyft.networks.ParameterTransform(\n",
    "        n_parameters, marginal_indices, online_z_score=parameter_online_z_score\n",
    "    )\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    n_marginals, n_block_parameters = parameter_transform.marginal_block_shape\n",
    "    \n",
    "    \n",
    "\n",
    "    marginal_classifier = marginal_classifier(\n",
    "        n_marginals,\n",
    "        n_observation_features + n_block_parameters,\n",
    "    )\n",
    "    \n",
    "\n",
    "    return swyft.networks.Network(\n",
    "        observation_transform,\n",
    "        parameter_transform,\n",
    "        marginal_classifier,\n",
    "    )\n",
    "    \n",
    "\n",
    "observation_key = 'image'\n",
    "marginal_indices, _ = swyft.utils.get_corner_marginal_indices(n_pars)\n",
    "observation_shapes = {\"image\": (L, L)}\n",
    "n_parameters = n_pars\n",
    "\n",
    "observation_transform = CustomObservationTransform(observation_key, observation_shapes)\n",
    "marginal_classifier = CustomMarginalClassifier\n",
    "    \n",
    "network = get_custom_marginal_classifier(\n",
    "    observation_transform = observation_transform,\n",
    "    marginal_indices = marginal_indices,\n",
    "#     observation_shapes = observation_shapes,\n",
    "    n_parameters= n_parameters,\n",
    "    marginal_classifier = marginal_classifier)\n",
    "\n",
    "mre = swyft.MarginalRatioEstimator(\n",
    "    marginal_indices = marginal_indices,\n",
    "    network = network,\n",
    "    device = DEVICE,\n",
    ")\n",
    "\n",
    "mre.train(dataset, max_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c394385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_losses(mre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8720677d",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = mre.network.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b908b57e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'network' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/scratch/ipykernel_5965/3546197804.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'network' is not defined"
     ]
    }
   ],
   "source": [
    "network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9455f36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coords(nmbins, L):\n",
    "    grid = np.linspace(lows[0], highs[0], L, endpoint = False)\n",
    "    x, y = np.meshgrid(grid, grid, indexing = 'xy')\n",
    "    ms = [torch.full((L*L,), m_i) for m_i in np.linspace(lows[-1], highs[-1], 2*nmbins+1)[1::2]]\n",
    "\n",
    "    coords = [np.array(()).reshape(1, -1)]\n",
    "    for m in ms:\n",
    "        coord = np.transpose(np.stack((x.flatten(), y.flatten(), m))).reshape(1, -1)\n",
    "        coords.append(coord)\n",
    "    return coords\n",
    "\n",
    "coords = get_coords(nmbins, L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "be0bca9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.5  , -2.5  ,  9.   , ...,  2.375,  2.375,  9.   ]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coords[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "252fc4c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 40)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7ced203b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.25, 0.75]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[m_i for m_i in np.linspace(0, 1, 2*nmbins+1)[1::2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a15d5cc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'image': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]])},\n",
       " array([-0.88097596,  2.03836966, 10.36712074, -1.60969079,  1.77212715,\n",
       "         9.47439289,  2.0167985 , -0.67231894,  8.71304035]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e09da7c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.5000, -2.3750, -2.2500, -2.1250, -2.0000, -1.8750, -1.7500, -1.6250,\n",
       "        -1.5000, -1.3750, -1.2500, -1.1250, -1.0000, -0.8750, -0.7500, -0.6250,\n",
       "        -0.5000, -0.3750, -0.2500, -0.1250,  0.0000,  0.1250,  0.2500,  0.3750,\n",
       "         0.5000,  0.6250,  0.7500,  0.8750,  1.0000,  1.1250,  1.2500,  1.3750,\n",
       "         1.5000,  1.6250,  1.7500,  1.8750,  2.0000,  2.1250,  2.2500,  2.3750])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = torch.linspace(lows[0], highs[0], L+1)[:-1]\n",
    "x, y = torch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8baa5c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_coords(nmbins, L):\n",
    "    grid = torch.linspace(0,(L-1)/L,L)\n",
    "    x, y = torch.meshgrid(grid, grid, indexing = 'xy')\n",
    "    ms = [torch.full((L*L,), m_i) for m_i in np.linspace(0, 1, 2*nmbins+1)[1::2]]\n",
    "\n",
    "    coords = [tensor(()).view(1, -1)]\n",
    "    for m in ms:\n",
    "        coord = torch.transpose(torch.stack((x.flatten(), y.flatten(), m)), 0, 1).reshape(1, -1)\n",
    "        coords.append(coord)\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3db704e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/scratch/ipykernel_32676/3017664728.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert 1 == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dad8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ad5483",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mre.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62f5cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor( mre.state_dict()['training_losses'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac80da37",
   "metadata": {},
   "outputs": [],
   "source": [
    "mre.state_dict()['validation_losses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025734e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mre._loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d4ba02",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(mre.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacf209e",
   "metadata": {},
   "outputs": [],
   "source": [
    "network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7176ca45",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 1 == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df073b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "post_name, post_path = get_post_path(sim_name, nmbins, lr, factor, patience)\n",
    "print(f'Training {post_name}!')\n",
    "\n",
    "torch.set_default_tensor_type(torch.FloatTensor)\n",
    "post = swyft.Posteriors(dataset)\n",
    "post.add(marginals, device = DEVICE, \n",
    "         tail_args = dict(nmbins = nmbins, lows = lows, highs = highs),\n",
    "         head = CustomHead, tail = CustomTail)\n",
    "post.train(marginals, max_epochs = max_epochs,\n",
    "           optimizer_args = dict(lr=lr),\n",
    "           scheduler_args = dict(factor = factor, patience = patience)\n",
    "          )\n",
    "post.save(post_path)\n",
    "\n",
    "print('Done!')\n",
    "print(f\"Total training time is {str(datetime.datetime.now() - time_start).split('.')[0]}!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
