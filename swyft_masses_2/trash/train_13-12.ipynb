{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87cdd258",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "\n",
    "import os\n",
    "import torch, pyro, numpy as np\n",
    "torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "\n",
    "import swyft\n",
    "import click\n",
    "\n",
    "\n",
    "DEVICE = 'cuda'\n",
    "\n",
    "from utils import *\n",
    "from network import CustomHead, CustomTail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c7c631f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, numpy as np\n",
    "torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "from torch import tensor\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms.functional as TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d86b9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch, pyro, numpy as np\n",
    "torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "from torch import tensor\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "\n",
    "from clipppy import load_config, Clipppy\n",
    "from clipppy.patches import torch_numpy\n",
    "from ruamel.yaml import YAML\n",
    "\n",
    "import swyft\n",
    "import pyro.distributions as dist\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c612e25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 0\n",
    "nsub = 3\n",
    "nsim = 100\n",
    "\n",
    "nmbins = 2\n",
    "\n",
    "lr = 1e-3\n",
    "factor = 1e-1\n",
    "patience = 5\n",
    "max_epochs = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c3399f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set definitions (should go to click)\n",
    "system_name = \"ngc4414\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d96b45ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Store _M_m0_nsub3_nsim100 exists!\n",
      "Loading existing store.\n",
      "Store has 88 simulations.\n",
      "Image has L = 40.\n"
     ]
    }
   ],
   "source": [
    "# Set utilities\n",
    "sim_name, sim_path = get_sim_path(m, nsub, nsim, system_name)\n",
    "store = swyft.DirectoryStore(path=sim_path)\n",
    "print(f'Store has {len(store)} simulations.')\n",
    "\n",
    "torch.set_default_tensor_type(torch.cuda.FloatTensor)  # HACK\n",
    "CONFIG = get_config(system_name, str(nsub), str(m))\n",
    "torch.set_default_tensor_type(torch.FloatTensor)\n",
    "\n",
    "prior, uv, lows, highs = get_prior(CONFIG)\n",
    "L = CONFIG.kwargs[\"defs\"][\"nx\"]\n",
    "print(f'Image has L = {L}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3ed1fbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prior(config: Clipppy):\n",
    "    \"\"\"\n",
    "    Set up subhalo parameter priors using a config\n",
    "    \"\"\"\n",
    "    main = config.umodel.alphas[\"main\"]\n",
    "    prior_p_sub = main.sub.pos_sampler.base_dist\n",
    "    m_sub_grid = main.sub.mass_sampler.y\n",
    "    lows = np.array(\n",
    "        [\n",
    "            prior_p_sub.low[0].item(),\n",
    "            prior_p_sub.low[1].item(),\n",
    "            m_sub_grid.min().log10().item(),\n",
    "        ]\n",
    "    )\n",
    "    highs = np.array(\n",
    "        [\n",
    "            prior_p_sub.high[0].item(),\n",
    "            prior_p_sub.high[1].item(),\n",
    "            m_sub_grid.max().log10().item(),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    \n",
    "    nsub = main.sub.nsub\n",
    "    lows_u = np.tile(lows, nsub)\n",
    "    highs_u = np.tile(highs, nsub)\n",
    "    \n",
    "    uv = lambda u: (highs_u - lows_u) * u + lows_u\n",
    "    return swyft.Prior(uv, nsub*3), uv, lows, highs\n",
    "\n",
    "prior, uv, lows, highs = get_prior(CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c9f3f54e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'swyft.prior'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/scratch/ipykernel_9342/3956651688.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mswyft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprior\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_diagonal_normal_prior\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'swyft.prior'"
     ]
    }
   ],
   "source": [
    "from swyft.prior import get_diagonal_normal_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6d1efa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from swyft.types import Array\n",
    "from swyft.utils import array_to_tensor, tensor_to_array\n",
    "from torch.distributions import Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "70149d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diagonal_normal_prior(loc: Array, scale: Array) -> swyft.Prior:\n",
    "    distribution = Normal(array_to_tensor(loc), array_to_tensor(scale))\n",
    "    return swyft.Prior.from_torch_distribution(distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d2e380bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'Prior' has no attribute 'from_torch_distribution'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/scratch/ipykernel_9342/2935750216.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_diagonal_normal_prior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/scratch/ipykernel_9342/2580413299.py\u001b[0m in \u001b[0;36mget_diagonal_normal_prior\u001b[0;34m(loc, scale)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_diagonal_normal_prior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mArray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mArray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mswyft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPrior\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mdistribution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mswyft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPrior\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_torch_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistribution\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'Prior' has no attribute 'from_torch_distribution'"
     ]
    }
   ],
   "source": [
    "get_diagonal_normal_prior(0.4, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "592690e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyrofit.lensing.distributions import get_default_shmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4e8928d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'swyft' has no attribute 'prior'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/scratch/ipykernel_9342/609634170.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mswyft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprior\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_diagonal_normal_prior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'swyft' has no attribute 'prior'"
     ]
    }
   ],
   "source": [
    "swyft.prior.get_diagonal_normal_prior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c51fc9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x_1', 'y_1', 'm_1', 'x_2', 'y_2', 'm_2', 'x_3', 'y_3', 'm_3']\n",
      "Creating new store.\n",
      "Store: Adding 10 new samples to simulator store.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pnames = [f'{z}_{i+1}' for i in range(nsub) for z in ['x', 'y', 'm']]\n",
    "print(pnames)\n",
    "simulator = swyft.Simulator(model = lambda v: simul(v, CONFIG), \n",
    "                            pnames = pnames,\n",
    "                            sim_shapes={\"image\": (L, L)})\n",
    "\n",
    "store = swyft.MemoryStore(simulator = simulator)\n",
    "store.add(10, prior)\n",
    "store.simulate()\n",
    "\n",
    "h = np.array([s[1] for s in store]).T\n",
    "\n",
    "for i in h:\n",
    "    plt.hist(i)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e5af005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up posterior\n",
    "torch.set_default_tensor_type(torch.FloatTensor)\n",
    "dataset = swyft.Dataset(nsim, prior, store)#, simhook = noise)\n",
    "marginals = [i for i in range(L**2)]\n",
    "post = swyft.Posteriors(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf0600b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training UNet_M_m0_nsub3_nsim100_nmbins2_lr-3.0_fac-1.0_pat5.pt!\n",
      "Training: lr=0.001, Epoch=4, VL=6658\n"
     ]
    }
   ],
   "source": [
    "class DoubleConv(swyft.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, 1, 1, bias=False), # bias = False becaise BatchNorm2d is set\n",
    "            nn.BatchNorm2d(out_channels), # BatchNorm2d were not known when paper came out\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNET(swyft.Module):\n",
    "    def __init__(self, in_channels, out_channels, features = [64, 128, 256, 512]):\n",
    "        super(UNET, self).__init__()\n",
    "                \n",
    "        self.ups = nn.ModuleList()\n",
    "        self.downs = nn.ModuleList()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2) # keep size the same\n",
    "        \n",
    "\n",
    "        # Down part of UNET\n",
    "        for feature in features:\n",
    "            self.downs.append(DoubleConv(in_channels, feature))\n",
    "            in_channels = feature\n",
    "\n",
    "        # Up part of UNET\n",
    "        for feature in reversed(features):\n",
    "            self.ups.append(\n",
    "                nn.ConvTranspose2d(\n",
    "                    feature*2, feature, kernel_size=2, stride=2,\n",
    "                )\n",
    "            )\n",
    "            self.ups.append(DoubleConv(feature*2, feature))\n",
    "\n",
    "        self.bottleneck = DoubleConv(features[-1], features[-1]*2)\n",
    "        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
    "        \n",
    "\n",
    "    def forward(self, x, target):\n",
    "                \n",
    "        x = x.unsqueeze(1)\n",
    "        skip_connections = []\n",
    "\n",
    "        for down in self.downs:\n",
    "            x = down(x)\n",
    "            skip_connections.append(x)\n",
    "            x = self.pool(x)\n",
    "\n",
    "        x = self.bottleneck(x)\n",
    "        skip_connections = skip_connections[::-1] # reverse list\n",
    "\n",
    "        # the upsampling\n",
    "        for idx in range(0, len(self.ups), 2): # step of 2 because we want up - double column - up - double column\n",
    "            x = self.ups[idx](x)\n",
    "            skip_connection = skip_connections[idx//2] # //2 because we want still steps of one\n",
    "\n",
    "            # if statement because we can put in shapes that are not divisble by two around 19:00 of video\n",
    "            if x.shape != skip_connection.shape: \n",
    "                x = TF.resize(x, size=skip_connection.shape[2:]) # hopefully does not impact accuracy too much\n",
    "\n",
    "            concat_skip = torch.cat((skip_connection, x), dim=1)\n",
    "            x = self.ups[idx+1](concat_skip)\n",
    "\n",
    "        x = self.final_conv(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "class CustomHead(swyft.Module):\n",
    "    def __init__(self, obs_shapes) -> None:\n",
    "        super().__init__(obs_shapes=obs_shapes)\n",
    "        self.n_features = torch.prod(tensor(obs_shapes['image']))\n",
    "#         self.onl_norm = OnlineNormalizationLayer(torch.Size([self.n_features]))\n",
    "\n",
    "    def forward(self, obs) -> torch.Tensor:\n",
    "        x = obs[\"image\"]\n",
    "        n_batch = len(x)\n",
    "        x = x.view(n_batch, self.n_features)\n",
    "#         x = self.onl_norm(x)    \n",
    "        return x\n",
    "\n",
    "class Mapping:\n",
    "#     def __init__(self):\n",
    "    def __init__(self, nmbins, L, lows, highs):\n",
    "#         super(Mapping, self).__init__()\n",
    "        self.nmbins = nmbins\n",
    "        self.L   = L\n",
    "        self.lows = lows\n",
    "        self.highs = highs\n",
    "\n",
    "    def coord_vu(self, coords_v):\n",
    "                        \n",
    "        n = len(coords_v[0])/3\n",
    "        assert n.is_integer()\n",
    "        n = int(n)\n",
    "\n",
    "        lows = np.full(coords_v.shape, np.tile(self.lows, n))\n",
    "        highs = np.full(coords_v.shape, np.tile(self.highs, n))   \n",
    "                \n",
    "        u = lambda v: (v - lows) / (highs - lows)\n",
    "        coords_u = u(coords_v)\n",
    "        return coords_u\n",
    "\n",
    "    def coord_to_map(self, XY_u):\n",
    "\n",
    "        \n",
    "        n_batch =  XY_u.shape[0]\n",
    "        n_coords = XY_u.shape[1]*2/3\n",
    "        assert n_coords.is_integer()\n",
    "\n",
    "        z = torch.zeros((n_batch, self.nmbins + 1, self.L, self.L), device = DEVICE)\n",
    "                \n",
    "        if not (n_batch == 0 or n_coords == 0):\n",
    "            \n",
    "            x_sub_u, y_sub_u, log10_m_sub_u = XY_u.view(-1,3).T.to(DEVICE)\n",
    "\n",
    "            x_i = torch.floor((x_sub_u*self.L).flatten()).type(torch.long) \n",
    "            y_i = torch.floor((y_sub_u*self.L).flatten()).type(torch.long) \n",
    "            m_i = torch.floor( log10_m_sub_u * self.nmbins ).type(torch.long) + 1\n",
    "            \n",
    "            i   = torch.floor(torch.arange(0, n_batch, 1/n_coords*2).to(DEVICE)).type(torch.long)\n",
    "            xx = tuple(torch.stack((i, m_i, y_i, x_i)))\n",
    "            z[xx] = 1\n",
    "\n",
    "            xx = tuple(torch.stack((i, torch.zeros_like(m_i), y_i, x_i)))\n",
    "            z[xx] = 1\n",
    "            \n",
    "        z[:,0] = 1 - z[:,0]\n",
    "\n",
    "        return z\n",
    "\n",
    "class CustomTail(swyft.Module):\n",
    "    def __init__(self, n_features, marginals, **tail_args):\n",
    "        super().__init__(n_features = n_features, marginals = marginals, **tail_args)\n",
    "        \n",
    "        \n",
    "        self.n_features = n_features\n",
    "        self.L = int(np.sqrt(n_features).item())\n",
    "        self.nmbins = tail_args['nmbins']\n",
    "        self.lows   = tail_args['lows']\n",
    "        self.highs  = tail_args['highs']\n",
    "        self.out_channels = self.nmbins + 1\n",
    "  \n",
    "        # self.Map  = Mapping()\n",
    "        self.Map  = Mapping(self.nmbins, self.L, self.lows, self.highs)\n",
    "        self.UNet = UNET(in_channels = 1, out_channels = self.out_channels)\n",
    "        \n",
    "       \n",
    "    def forward(self, sims, target):\n",
    "        \n",
    "        sims = sims.view(-1, self.L, self.L)\n",
    "        \n",
    "        x = self.UNet(sims, target)\n",
    "        z = self.Map.coord_to_map(target)\n",
    "        \n",
    "        x = x * z\n",
    "        x = x.view(-1, self.n_features * self.out_channels)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "# Train\n",
    "post_name, post_path = get_post_path(sim_name, nmbins, lr, factor, patience)\n",
    "print(f'Training {post_name}!')\n",
    "\n",
    "torch.set_default_tensor_type(torch.FloatTensor)\n",
    "post = swyft.Posteriors(dataset)\n",
    "post.add(marginals, device = DEVICE, \n",
    "         tail_args = dict(nmbins = nmbins, lows = lows, highs = highs),\n",
    "         head = CustomHead, tail = CustomTail)\n",
    "post.train(marginals, max_epochs = max_epochs,\n",
    "           optimizer_args = dict(lr=lr),\n",
    "           scheduler_args = dict(factor = factor, patience = patience)\n",
    "          )\n",
    "# post.save(post_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4885267",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Done!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
